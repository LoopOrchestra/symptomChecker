import time
import os
import getpass
import pandas as pd
from sentence_transformers import SentenceTransformer
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import CSVLoader
from langchain.chains import RetrievalQA
from langchain_groq import ChatGroq
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.document_loaders import PyPDFLoader
from langchain.document_loaders.merge import MergedDataLoader
from langchain.prompts import PromptTemplate   # üëà nuovo import

### 1Ô∏è‚É£ Caricamento API Key di Groq ###
if not os.environ.get("GROQ_API_KEY"):
    os.environ["GROQ_API_KEY"] = getpass.getpass("Enter API key for Groq: ")

### 2Ô∏è‚É£ Carichiamo il CSV ###
csv_path = "/Users/aishaalbabrown/Desktop/LoopAi/Symptom checker material/MIO  SECONDO FIGLIO.csv"
csv_loader = CSVLoader(file_path=csv_path)

### 3Ô∏è‚É£ Carichiamo il PDF ###
pdf_paths = ['/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/KIDNEY CANCER.pdf',
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/ACUTE LYMPHOBLASTIC LEUKEMIA.docx.pdf', 
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/BRAIN CANCER 1.1.pdf',
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/BRAIN CANCER 1.2.pdf',
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/BRAIN CANCER 1.3.pdf',
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/BRAIN CANCER 1.4.pdf',
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/BRAIN CANCER.docx.pdf',
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/CHEST X_RAY_FOR_PNEUMONIA.docx.pdf',
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/EYE DISEASES CLASSIFICATION.docx.pdf',
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/LUNG AND COLON CANCER.docx.pdf',
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/SKIN CANCER 1.1.pdf',
            '/Users/aishaalbabrown/Desktop/Lavoro loopai/Medical documentation/SKIN CANCER DETECTION.docx.pdf']
pdf_loaders = [PyPDFLoader(path) for path in pdf_paths]

### 4Ô∏è‚É£ Uniamo CSV + PDF ###
merged_loader = MergedDataLoader(loaders=[csv_loader] + pdf_loaders)
docs = merged_loader.load()

### 5Ô∏è‚É£ Creiamo gli embeddings con SBERT ###
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

### 6Ô∏è‚É£ Creiamo il vectorstore FAISS ###
vectorstore = FAISS.from_documents(docs, embeddings)
retriever = vectorstore.as_retriever()

### 7Ô∏è‚É£ Impostiamo il modello LLM di Groq ###
llm = ChatGroq(model_name="llama-3.1-8b-instant", temperature=0.5)

### 8Ô∏è‚É£ Prompt medico SAFE per il symptom checker ###
SYSTEM_PROMPT = """
You are a medical information assistant, NOT a doctor.

You must follow these rules:
- Use ONLY the information contained in the context below.
- If the context is not enough to answer safely, say you don't know
  and recommend talking to a doctor.
- Never give a definitive diagnosis.
- Never invent diseases, drugs, lab values, or numbers that are not in the context.
- Always be cautious with serious symptoms (chest pain, difficulty breathing,
  neurological symptoms, severe pain, blood in urine, etc.): in these cases
  suggest urgent medical evaluation.
- Answer in clear, simple English, in 1‚Äì3 short paragraphs.

Context:
{context}

Question:
{question}

Your answer (in English). At the end, add this sentence:
"This is not a medical diagnosis. Please consult a healthcare professional, and seek urgent care if symptoms are severe or worsening."
"""

prompt = PromptTemplate(
    input_variables=["context", "question"],
    template=SYSTEM_PROMPT,
)

### 9Ô∏è‚É£ Creiamo la catena di interrogazione con RetrievalQA ###
qa_chain = RetrievalQA.from_chain_type(
    llm,
    retriever=retriever,
    chain_type="stuff",
    return_source_documents=True,          # üëà per avere i documenti usati
    chain_type_kwargs={"prompt": prompt},  # üëà usiamo il prompt sicuro
)

### üîü Facciamo una query di prova ###
query = "What information is present in the file?"
start = time.time()
response = qa_chain.invoke({"query": query})
latency = time.time() - start

answer = response.get("result", response)
source_docs = response.get("source_documents", [])
n_docs = len(source_docs)

print("\nüîç Initial test query:")
print("Q:", query)
print("\nüìù Answer:", answer)
print(f"‚è± Latency: {latency:.2f} s | üìö Source docs: {n_docs}")

# (opzionale) vedere da dove ha preso le informazioni
# for i, doc in enumerate(source_docs):
#     print(f"\n--- Source doc {i+1} ---")
#     print(doc.page_content[:400])

### 1Ô∏è‚É£1Ô∏è‚É£ Loop interattivo ###
while True:
    query = input("\nWrite your question (or 'exit' per uscire): ")
    if query.lower() == "exit":
        print("Closing of RAG system. Farewell!")
        break
    
    start = time.time()
    response = qa_chain.invoke({"query": query})
    latency = time.time() - start

    answer = response.get("result", response)
    source_docs = response.get("source_documents", [])
    n_docs = len(source_docs)

    print("\nüìù Answer:", answer)
    print(f"‚è± Latency: {latency:.2f} s | üìö Source docs: {n_docs}")
